%
% exposit.tex
%    システム制御情報学会  Ａ４版クラスファイル
%    scitrans.cls のサンプル（解説・総説・展望記事のテンプレートファイル）
%
\documentclass[J]{scitrans}
\usepackage[dvipdfmx]{graphicx}
%\usepackage[whole]{bxcjkjatype}
%
%               Usage:  \documentclass[J]{scitrans} (和文の場合)
%                       \documentclass[E]{scitrans} (英文の場合)
%
% 年, 巻, 号 ページの設定
%
\UseRawInputEncoding
\appearyear{xxx}
\vol{xxx}
\numberinvol{xx}
\setcounter{page}{1}
\setcounter{volumepage}{1}

\Journal{解説}{『特集名』}{\expositry}      %% 解説の時
%%\Journal{総説}{『特集名』}{\survey}       %% 総説の時
%%\Journal{展望}{『特集名』}{\technicalview}%%  展望の時

%%\Journal{カテゴリ}{}      %% 特集号でない時は, 第2引数を空に

%%\ForSubmission            %% 提出前に一度コメントをはずして
                            %% 英文題目および著者名をご確認ください
\def\ddash{\rule[0.33zh]{2zw}{.03zh}}
\begin{document}

\title{埋め込み法が拓くネットワーク科学の新展開}
\author{幸若 完壮*}

\etitle{A New Paradigm for Network Science with Graph Embeddings}
\eauthor{Sadamori {\sc Kojaku}*}
\headingtitle{埋め込み法が切り拓くネットワーク分析の新展開}
\headingauthors{システム}

\maketitle

\acceptdate{xxx年xx月xx日}

\address{*}{Luddy School of Informatics, Computing, and Engineering, Indiana University Bloomington, USA}

\keywords{ネットワーク埋め込み法, 科学の科学, 機械学習}

%%% つぎの \input を削除し，本文を書き出して下さい．
%-----------------
\section{はじめに}
%-----------------
\label{sec:introduction}

友好関係、 銀行の融資関係、食物連鎖など社会や自然界のあらゆる場所にネットワークは存在する。
ネットワークは人間や銀行といった「モノ」と友好関係や取引関係といった「つながり」からなり、 
モノがお互いに影響を与え合うことで突発的で大規模な現象、例えば感染の拡大や倒産の連鎖、異常繁殖などの一因となっている\cite{}。
%ネットワークはモノ（頂点）とモノのつながり(枝)の集まりである。
%これらのつながりを介してモノとモノがお互いに影響しあい、 感染症の拡散や倒産の連鎖、生物の異常繁殖といった突発的で大規模な現象が引き起こる\cite{}。
%5例えば、 感染症は多くの人と接触機会を持つ人に伝わりやすく、その人を介してさらに多くの人に伝わることで爆発的な感染の連鎖が起こる\cite{}。

デジタル技術の進歩によって様々なネットワークがデータとして記録される一方で、その分析には超えるべき大きな障壁がある。
それは、ネットワークはモノやつながりの集まりではないため、一般的な手法でデータ分析しても十分な結果が得られないという障壁である。
例えば、ある感染症の感染疑いがある人を、人と人の接触データから見つける場合、感染者と接触した人を調べるだけでは不十分である。
なぜなら直接の接触がなくても、例えば共通の友人を介して感染することや、友人の友人、さらにその友人を介して感染する可能性もある。
そのため、感染疑いのある人を発見するためには個々の接触だけでなく、ネットワーク全体の接触関係を考えなくてはならない。
このように、ネットワークではつながりの組み合せが重要な意味を持つため、 ネットワーク分析のための専用の手法や理論が必要となる。

この障壁を解決する方法として、ネットワークをベクトルに圧縮変換する技術\ddash 埋め込み法\ddash が登場し、新たな展開を見せている。
埋め込み法は、 頂点をある空間上の点として捉えて、頂点の位置関係によってその複雑な関係を表現する手法である(図1)。
各頂点は位置を表すベクトルで表現されるため、ベクトルデータを入力とする様々な統計的・機械学習的なデータ分析法がネットワーク分析に利用可能となる。

本稿では、 埋め込み法が拓くネットワーク科学の新たな展開について概説する。
具体的に、 前半部では埋め込み法の代表的な手法とその応用例を紹介し基本的な考えと仕組みを説明する。
後半部では、 埋め込み法の応用事例として科学雑誌の引用ネットワークから学術分野のマップを作成した事例を紹介する。

\section{埋め込み法}

\subsection{自然言語処理の埋め込み法}

2010年代に提案されたネットワーク埋め込み法の多くは、自然言語処理で開発された埋め込み法が元になっている。
自然言語処理の大きな課題として人間の言語を機械で処理できる形にどのように変換するかという課題がある。
率直に考えれば、1つの単語に対して1つの数字を割り当てれば一応は数値化できる。
例えば、「値段は高いが質が低い料理」という文を「値段,高い,質,低い,料理」と区切って各単語に1つの数字を割り当てて「1,2,3,4,5」と表現する。
これは局所表現と呼ばれる。
局所表現は「高いの対義語は低いである」といった単語同士の関係を捉えられず、また変換した数字を使って1+2=3といった演算ができない。
%そのため、局所表現は「機械で読めるが扱いにくい」表現である。

この局所表現の欠点を解決したのが「分散表現」だ。
分散表現は、各単語をベクトル空間上の点と捉え、単語同士の意味の共通性や相似性を空間上の位置関係で記述する強力な表現方法である。
% (図がほしい)
例えば、国名と都市名を分散表現で記述しよう(図1)。国名同士、都市名同士を近くに配置することで「国」と「都市」の区別を表現できる。
また、「フランスとパリ」、「日本と東京」といった相似な関係も表現可能である。
ベクトル空間の次元を増やせば、より複雑な単語同士の関係を表現することもできる。

%分散表現が高い注目を集める一方で、膨大な単語の配置を決定する難しさやそのために必要な計算量が大きいことが障害となり、分散表現の実践が停滞していた。
%この問題を解決し脚光を浴びた手法がこれから紹介する``Word2Vec''である。

\subsection{Word2Vec}

分散表現は膨大な単語の配置を決定する難しさや計算量が大きいといった実用上の課題のため実践が進まなかった。
これらの課題を解決し、自然言語処理に大きな進展をもたらした手法が「Word2Vec」である。

Word2Vecはニューラルネットワークを利用した手法である。
このニューラルネットワークは2層から構成され、その単純さから膨大なデータを高速に学習することができる。
学習方法の違いによってSkip-gram法とCBOW(Continuous Bag-of-Words)法の2つのモデルがあるが、本稿ではSkip-gram法を紹介する。

Skip-gram法はニューラルネットワークを訓練するために、文章中のある1つの単語を入力としてその周辺に現れる単語を予測する問題を解かせる(図2)。
周辺に現れる単語は入力の単語が使われている文脈を表すと考えて、文脈単語とも呼ばれる。
入力と出力に与える単語はニューラルネットワークが処理しやすいようにone-hotベクトルで表現する。
one-hotベクトルは1つの要素が``1''で他の全てが要素が``0''のベクトルであり、``1''が出現する場所で単語を区別する。
訓練後、各単語をニューラルネットワークに入力し、中間層の信号ベクトルをその単語の分散表現とする。

Word2Vecの分散表現は何を表しているのだろうか？
これを理解するために、入力した単語の情報がニューラルネットワークでどのように処理されるか見てみよう。
ニューラルネットワークの入力は単語を表す高次元のone-hotベクトルである。
このベクトルは入力層から中間層に渡ってより小さな次元のベクトルに変換され、その後に中間層から出力層に渡って文脈を表すベクトルに変換される。
この小さく圧縮されたベクトルが入力単語の分散表現である。
圧縮されたベクトルはその後文脈単語へ変換されるため、Word2Vecの分散表現は各単語が使われる「文脈」を表現していると見ることができる。

ではWord2Vecを使って日本語の文章を分散表現を見てみよう。
本稿では日本語のWikipediaで学習済みのWord2Vec\cite{park2016}を用いて都道府県と野球球団の分散表現を得たものが図\ref{}である。

xxxx

次に、同じ学習済みのWord2Vecを用いて

\subsection{ネットワークの埋め込み}


Word2Vecとは, 自然言語処理



%- なぜ埋め込みか
%    - NLPの要請に触れておく
%- どうやって埋め込む？
%　  - Neural Netで図的な解説
%    - 情報圧縮と解凍
- 自然言語処理での成功例
    - Analogy test
    - Material2Vec
- Networkの埋め込み
    - Grapから文の生成
- Airport netでの応用

\section{科学の地図を作る}

- Journal2Vec
- Translational axis




%-----------------
\section{おわりに}
%-----------------


% 謝辞
%------------------
\acknowledgement
%-----------------



\authorbiography{幸,若,　,完,壮}{こう,じゃく,,さだ,もり}{非正会員}{%
 2015年9月××大学大学院工学研究科○○工学専攻△△課程修了．
 同年X月××助手．19XX年X月××となり現在に至る．
 ××の研究に従事．
 ××などの会員．}

%\authorbiography{佐,藤,　,花,子}{さ,とう,,はな,こ}{正会員}{%
%  19XX年X月××大学大学院工学研究科○○工学専攻△△課程修了．
%  同年X月××助手．19XX年X月××となり現在に至る．
%  ××の研究に従事．
%  ××などの会員．}

%\authorbiography{田,中,　,次,郎}{た,なか,,じ,ろう}{正会員}{%
%  19XX年X月××大学大学院工学研究科○○工学専攻△△課程修了．
%  同年X月××助手．19XX年X月××となり現在に至る．
%  ××の研究に従事．
%  ××などの会員．}

\end{document}
%
%% end of exposit.tex
